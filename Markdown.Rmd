title: "Veri Tipi Belirleme"
author: "Bükra Doğaner"
date: '2022-03-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

çalışacağımız verisetinin içeri aktarılması için `read.csv`` fonksiyonu kullanılır. 
içeri aktarcağımız lokal dosya yolu yada uzak sunucuda tutulan dosyanın yolu fonksiyona girdi olarak verilir. 

```{r}
veriseti <- read.csv("fin500.csv")
```

veriseti yüklendikten sonra veriseti içeriğini kontrol etmek üzere `head()` ve `tail()` fonksiyonları kullanılır


```{r}
head(veriseti,15)

tail(veriseti,2) 
```
verisetinde yer alan dataların yapısını görmek için str fonksiyonu kullanılır

```{r}
str(veriseti) 
```

Veriseti içindeki tek bir stünün okunması için veriseti$xx komutu kullanılır. Örnek olarak Industry stünunun görüntülenmesi için 

```{r}
veriseti$Industry
```

Verisetine dair özet bilgi için summary() fonksiyonu kullanılır.

```{r}
summary(veriseti) 
```

verisetinde yer alan verilerin yapısının değiştirilmesi için veriseti$() <- as.factor(veriseti$veriseti$değişiklik yapılacak sütun) fonksiyonu kullanılır. Verilerin doğru analiz edilmesi için verisetinde yer alan bilgilerin doğru şekilde tanımlanması gerekmektedir. Tüm veriler tek tek incelenerek tanımlaması yapılmalıdır.

```{r}
veriseti$Industry <- as.factor(veriseti$Industry)
veriseti$Inception <- as.factor(veriseti$Inception)
veriseti$State <- as.factor(veriseti$State)
veriseti$City <- as.factor(veriseti$City)
veriseti$Revenue <- as.character(veriseti$Revenue)
```

Verilerin istenilen formata uygun olması için 'veri temizliği' işlemi yapılmalıdır. Bu işlemde gsub() komutu kullanılabilmektedir. Verilerin rakamsal veri olarak algılanması için sayıların sonunda yer alan dolar kelimesinin silinmesi fonksiyonu aşağıdaki gibidir. gsub("çıkarılması gereken değer", "yerine konulacak değer", veriseti$değişiklik yapılacak sütun)

```{r}
veriseti$Expenses <- gsub(" Dollars", "", veriseti$Expenses)
veriseti$Expenses <- gsub(",", "", veriseti$Expenses) 
``` 

işlem kalabalığı olmaması açısından gsub fonksiyonunun kullanıldığı işlemi aşağıdaki şekilde birleştirmek mümkündür. 

```{r}
veriseti$Growth <- as.numeric(gsub("%", "", veriseti$Growth))
``` 

Verilerde yer alan $ gibi R programında bir anlam ifade eden karakterlerle ilgili işlem yapılacağı zaman başına \\ koyularak karakterin programda bir anlam ifade etmediği tanımlanır.

```{r}
veriseti$Revenue <- gsub("\\$","", veriseti$Revenue)
``` 


verilerin son durumu aşağıdaki gibidir.

```{r}
str(veriseti)
```

"İkinci Ders"

alttaki scale formülü
$$  
\frac{X{i}}{\sigma{x}}
$$
Yeni veri seti ile çalışmaya başladık
Matematiksel işlemler ile çalışacağımızdan dolayı `caret` paketini yükledik. Daha sonra R'da yerleşik veri kümesi olan `iris` veri kümesini çağırdık ve `iris` veri kümesinin yapısını ve özetini ortaya koyduk.
```{r}
library(caret)
data(iris)
str(iris)
```
#verisetindeki tüm satırlar ile 1. ve 4. sütunlar arasını aldık. Eğer 1. 3. ve 5. sütunları almak isteseydik C(1,3,5) komutunu uygulamamız gerekecekti.
```{r}
summary(iris[,1:4])
```
Verisetimizde uygulayacağımız dönüşümler (matematiksel işlemler) için `preProcess` komutunu kullandık ve `preProcess` altındaki `scale` paketini çağırdık. Scale fonksiyonu her bir gözlemi o serinin standart sapmasına göre oranlamaktadır.
```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("scale"))
print(preProcessParams)
```
$$
\frac{x_(i)}{\sigma_(x)}
$$
İşlemleri belirli veri kümelerine uygulamak için `predict` komutunu kullandık. Sonrasında veri setini görmek için summary fonksiyonu kullandık.
```{r}
scaled <- predict(preProcessParams, iris[,1:4]) #predict fonksiyonunu dönüştürerek iris 1:4 e yazdırdık.
summary(scaled)
```
`preProcess` altındaki `scale` paketini çağırdık ve dönüşüm yaparak yazdırdık. Center fonksiyonu her bir değişkenin ortalamalarından çıkartılmış halini vermektedir.

```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("center")) #xi-xmü yaptık
print(preProcessParams)

centered <-  predict(preProcessParams, iris[,1:4])
summary(centered)
```
$$
x_{i}-\bar{X}_{x}
$$
Standardizasyon uygulayabilmek için;
```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("center", "scale"))
print(preProcessParams)

standardized <- predict(preProcessParams, iris[,1:4])
summary(standardized)
```
$$
\frac{x_{i}-\mu{x}}{\sigma_{x}}
$$

Normalizasyon uygulayabilmek için;

```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("range")) 
print(preProcessParams)
normalized <- predict(preProcessParams, iris[,1:4])
summary(normalized)
```

$$
\frac{x-min\left(x \right )}{max\left(x \right )-min\left(x \right )}
$$
`boxcox` dönüşümü, normal olarak dağıtılmamış bir veri kümesini daha normal dağılmış bir veri kümesine dönüştürmek için yaygın olarak kullanılan bir yöntemdir. `boxcox` uygulayabilmek için;
```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("BoxCox"))
print(preProcessParams)

boxcox <- predict(preProcessParams, iris[,1:4])
summary(boxcox)
```

$$
y\left( \lambda \right )=\left\{\begin{matrix}\frac{y^ \lambda -1 }{\lambda}, & if \lambda\neq 0\\ log\left (y  \right ), & if \lambda = 0 \end{matrix}\right.
$$

`Yeo-Johnson` dönüşümü, normalleştirme dönüşümünü hesaplar. `yeojohnson` uygulabilmek için;

```{r}
preProcessParams <- preProcess(iris[,1:4], method=c("YeoJohnson"))
print(preProcessParams)

yeojohnson <- predict(preProcessParams, iris[,1:4])
summary(yeojohnson)
```
$$
\psi \left( \lambda, y \right )=

\left\{\begin{matrix}

({(\lambda +1)^\lambda -1)/\lambda}, & if \lambda\neq 0, y\geq 0\\

log\left (y+1  \right ), & if \lambda = 0, y\geq 0 \\ 

-[(-y+1)^{2-\lambda }-1)]/(2-\lambda), & if \lambda \neq  2, y< 0 \\ 

-log\left (-y+1  \right ), & if \lambda = 2, y< 0\end{matrix}\right.
$$
Resampling yani yeniden örnekleme yapacağız. Bunun için Caret Package yükledik ve verimizi çağırdık.
```{r}
library(caret) #load caret package
data(iris) #Load the dataset
```
Bunun için Boolstrap yöntemi kullandık ve verilerden yeniden 100 verilik örneklem oluştuduk.
```{r}
train_control <- trainControl(method="boot", number = 100)
```
Veri setinde %80/%20 eğitim/test bölünmesini tanımladık
```{r}
split=0.80
trainIndex <- createDataPartition(iris$Species, p=split, list=FALSE)
```
80/20 olarak böldüğümüz verinin 80lik kısımını yani eğitim datasını çağırdık. 5 fold oluştuğunu gördük.  Veriyi her taraftan inceleyerek en uygun test datası nerden elde edilir onu hesaplamaya çalıştık.
```{r}
data_train <- iris[trainIndex,]
```
20'lik kısmı görmek için ise formülde başına eksi koyduk. 
```{r}
data_test <- iris[-trainIndex,]
```
Çapraz doğrulama yaptık. One Out modelini seçtik. Bu bir model doğrulama tekniğidir. Eğittiğimiz modelin amacı doğrultusunda ne kadar düzgün şekilde ilerlediğini, hatalar olup olmadığını, kontrol etmek için kullanılır. Eğitim kontrolünü tanımlattık..
```{r}
# Leave One Out Cross Validation (LOOCV)
library(caret)
#load the iris dataset
data(iris)
#define training control
train_control <- trainControl(method="LOOCV")
```

Ayrıca bir de K-Fold Cross Validation uyguladık. Bu yöntem de sınıflandırma modellerinin değerlendirilmesi ve modelin eğitilmesi için veri setini parçalara ayırma yöntemlerinden biridir. Burada 10 fold oluşturduk.
```{r}
#load the library
library(caret)
#load the iris dataset
data(iris)
#define training control
#k fold number => number
train_control <- trainControl(method="cv", number=10)
```
Lineer regresyon uygulaması yapmaya başladık. Regresyonu R programında tanımlı 'cars' paketi üzerinden uygulamak için veriyi çağırdık ve veriyi inceledik.
```{r}
head(cars)
str(cars)
summary(cars)
```
Verideki kolon isimlerine bakmak için 'names' fonksiyonunu kullandık. Bu fonksiyon Veri setindeki 'header'ları gösterir.
```{r}
names(cars)
```
Verilerin regresyon modeli kurmaya uygun olup olmadığını kontrol etmek için saçılma diyagramı çizdirdik. Aynı şekilde bu amaçla değişkenler arasındaki korelasyona baktık.
```{r}
scatter.smooth(x=cars$speed, y=cars$dist, main="Saçılma Diyagramı")
cor(cars$speed, cars$dist)
```
Veri üzerinde lm fonksiyonu ile lineer regresyon modeli kurduk. Bu modelde distance bağımlı değişkenken speed bağımsız değişken olarak yer aldı. Daha sonra bu modeli yazdırdık ve özetine baktık.
```{r}
GenelModel <- lm(dist ~ speed, data=cars)
print(GenelModel)
summary(GenelModel)
```
Akaike Bilgi Kriteri ve Bayesian Bilgi Kriteri değerine baktık.AIC herhangi bir tahmini istatistiksel modelin uygunluğunun bir ölçüsü olarak adlandırılmaktadır.BIC ise farklı parametre sayılarına sahip parametrik modeller sınıfı arasında bir model seçimi türüdür. Bu iki değerin de küçük olması istenmektedir.

```{r}
AIC(GenelModel)
BIC(GenelModel)
```
Makine öğrenmesi bu bölüm ve sonrasında uygulanmıştır. Rastgele örnekleme sonuçlarını çoğaltmak için seed(tohum) ayarladık. Hepimiz aynı rassal sayıları bulmak için değer olarak 100 yazdık. Daha sonra verilerin %80'i ile 1'den n'e kadar index değerleri ürettik.
```{r}
set.seed(100)
trainingRowIndex <- sample(1:nrow(cars), 0.8*nrow(cars))
```
Veri setini bölerek eğitim ve test verisi olarak parçaladık. Model eğitim verisini ve test verisini oluşturduk. Test verisi oluşturuken formülasyonda başa '-' işareti ekledik.
```{r}
trainingData <- cars[trainingRowIndex, ] 
View(trainingData)
testData <- cars[-trainingRowIndex, ] 
View(testData)
```
Eğitim verisi üzerinden yeniden model kurduk. Modelde distance bağımlı değişken, speed bağımsız değişken olarak yer aldı.
lmmod fonksiyonunu kullandık. Bu fonksiyonu kullanarak model test verisindeki 'speed' değişkenlerini modele koyarak 'distance' değişkenlerini tahmnin etmekte. Bu tahmin edilen verileri distPred olarak adlandırdık.
Oluşan verilerin özetine baktık ancak çok anlamlı olmadığını gördük. Ardından yine Akaike Bilgi Kriteri değerini kontrol ettik. Değerin biraz kötülerştiğini gördük.
```{r}
lmMod <- lm(dist ~ speed, data=trainingData)
distPred <- predict(lmMod, testData)
print(distPred)
summary(lmMod)
AIC(lmMod)
```
Gerçekleşen verileri ve model ile tahmin edilen verileri net görebilmek için yanyana yazdırdık.
Gerçekleşen veriler ile tahmin edilen verilerin ne kadar örtüştüğünü görmek amacıyla korelasyonlarına baktık.
```{r}
actuals_preds <- data.frame(cbind(gercek=testData$dist, tahmin=distPred))
correlation_accuracy <- cor(actuals_preds)
print(correlation_accuracy)
head(actuals_preds)
```
#min_max_accuracy <- mean(apply(actuals_preds), 1, min) / apply(actuals_preds, 1, max)) 
MAPE yani mean absolute percentage error değerine baktık. Bu değer ortalama hata bir makine öğrenmesi modelinin öngördüğü tahmin değerleri ile gerçek değerlerin arasındaki ortalama hatadır.
Yazdırarak modelin %50 hata yapmış olduğunu gördük
```{r}
mape <- mean(abs((actuals_preds$tahmin - actuals_preds$gercek))/actuals_preds$gercek)
print(mape)
```
Modelde makine öğrenmesi kısmı asıl burada başladı.
Bunun için kütüphanden DAAG paketini yükledik.
CVlm (cross validation lm) fonksiyonu DAAG paketi yüklenince gelmektedir. Burada form formülasyonu linear modeln formülasyonunu, m ise modelin oluşturmasını istediğimiz küme sayısını belirtmektedir. Burada  yazarak Veri setini 5 parçaya böldürmüş ve 5 ayrı regresyon modeli oluşturmuş olduk. Bu 5 parça içerisinde test verisi sürekli değişti. Bu sayede makine öğrenmesi yapmış olduk.
Daha sonra MSE yani mean squarred error (ortalama hata karesi) değerine baktık.Bu hata bir tahmincinin ortalama karesi alınmış hatası veya ortalama karesi alınmış sapma, hataların karelerinin ortalamasını, yani tahmin edilen değerler ile gerçek değer arasındaki ortalama karesi alınmış farkı ölçmektedir.
```{r}
library(DAAG)
cvResults <- suppressWarnings(CVlm(cars, form.lm = dist ~speed, m=5, dots = FALSE, seed=29, legend.pos ="topleft", printit = FALSE, main="CV Dogrusal Regresyon"));
attr(cvResults, 'ms')